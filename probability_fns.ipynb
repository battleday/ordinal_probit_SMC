{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8091cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a2ece",
   "metadata": {},
   "source": [
    "## Probability functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the basic probabilty functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e48b734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_suite(TestCase):\n",
    "    loader = unittest.TestLoader()\n",
    "    suite = loader.loadTestsFromTestCase(TestCase)\n",
    "    return suite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c29955d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unittest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_47277/581776484.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mProbabilityFunctionsTestSuite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munittest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTestCase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgauss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unittest' is not defined"
     ]
    }
   ],
   "source": [
    "def mu_prior(mu, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on mu. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of mu.\"\"\"\n",
    "    \n",
    "    p = stats.norm.pdf(mu, mu_0, sigma_0)\n",
    "    \n",
    "    if debug:\n",
    "        assert 0 < p < 1, \"p not in right range: {}\".format(p)\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "def mus_log_prior(mus, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all mus. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mus: vector of scalar value in Reals corresponding to mus;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation for all mus; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of mus.\"\"\"\n",
    "    \n",
    "    LP = 0 # log prior\n",
    "    \n",
    "    for mu in mus: # ignore first and last value, as these aren't really variables\n",
    "        LP += np.log(mu_prior(mu, mu_0, sigma_0, printing, debug))\n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "            \n",
    "    return LP\n",
    "\n",
    "def mu_proposal(mu, sigma_prop, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual mu. \n",
    "    Simple random walk. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma_prop: standard deviation of jumps; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    mu_star: new proposed value for mu.\"\"\"\n",
    "    \n",
    "    mu_star = np.random.normal(mu, sigma_prop)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(mu_star, float) is True, \"type of LP is not scalar: {}\".format(type(mu_star))\n",
    "        \n",
    "    return mu_star\n",
    "\n",
    "def mu_log_jump_probs(mu, mu_star, sigma_prop, printing=False, debug=False):\n",
    "    \"\"\"While using a symmetric (i.e., non-truncated) proposal, this is merely\"\"\"\n",
    "    return 0  \n",
    "\n",
    "def sigma_prior(sigma, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on sigma. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: scalar value in (0, inf);\n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of sigma.\"\"\"\n",
    "    if lower_0 <= sigma <= upper_0:\n",
    "        p = 1/(upper_0-lower_0)\n",
    "    else:\n",
    "        p = 0.0\n",
    "    \n",
    "    if debug:\n",
    "        assert 0 <= p <= 1, \"p not in right range: {}\".format(p)\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "def sigmas_log_prior(sigmas, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all sigmas. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigmas: vector of scalar values in (0, inf);\n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of sigmas.\"\"\"\n",
    "    \n",
    "    LP = 0 # log prior\n",
    "    \n",
    "    for sigma in sigmas: # ignore first and last value, as these aren't really variables\n",
    "        LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LP, float), \"type of LP is not scalar: {}\".format(type(LP))\n",
    "            \n",
    "    return LP\n",
    "\n",
    "def sigma_proposal(sigma, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual sigma. \n",
    "    Simple random walk that reflects on both sides of interval.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: latent standard deviation; scalar value in (0, inf);\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    sigma_star: new proposed value for sigma.\"\"\"\n",
    "    \n",
    "    sigma_star = stats.truncnorm.rvs(lower_0, upper_0, sigma, sigma_prop)\n",
    "    if debug:\n",
    "        assert lower_0 <= sigma_star <= upper_0\n",
    "    return sigma_star\n",
    "\n",
    "def sigma_proposal_prob(sigma_new, sigma_old, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis-Hastings sampler to evaluate proposal for individual sigma. \n",
    "    Simple random walk that reflects on both sides of interval. Note, have to convert lower and upper\n",
    "    to standard normal form; scipy then reconverts based on scale and location parameters.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma_old: latent standard deviation; scalar value in (lower_0, upper_0);\n",
    "    sigma_new: latent standard deviation; scalar value in (lower_0, upper_0);\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: lower end of range;\n",
    "    upper_0: upper end of range; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: probability for value of sigma.\"\"\"\n",
    "    a = (lower_0 - sigma_old)/sigma_prop\n",
    "    b = (upper_0 - sigma_old)/sigma_prop\n",
    "    p = stats.truncnorm.pdf(sigma_new, a, b, sigma_old, sigma_prop)\n",
    "    if debug:\n",
    "        assert 0 <= p <= 1, \"p not in right range: {}\".format(p)\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "\n",
    "def sigma_log_jump_probs(sigma, sigma_star, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"If using truncated normal, no longer symmetric. This is now Metropolis-Hastings algorithm, \n",
    "    and we have to add log of ratio of proposal probabilities to log of acceptance probabilities.\n",
    "    \n",
    "        Inputs\n",
    "    -------------------\n",
    "    sigma: latent standard deviation; scalar value in (lower, upper);\n",
    "    sigma_star: proposed value for latent standard deviation; scalar value in (lower, upper);\n",
    "    sigma_prop: scale of jump; \n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log probability of ratio of jump probabilities.\"\"\"\n",
    "    # first argument is proposal, second mean\n",
    "    LP = np.log(sigma_proposal_prob(sigma, sigma_star, sigma_prop, \n",
    "                                    lower_0, upper_0, printing, debug)) - np.log(sigma_proposal_prob(sigma_star, sigma, sigma_prop, \n",
    "                                                                                                 lower_0, upper_0, printing, debug))\n",
    "        \n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        \n",
    "    return LP\n",
    "\n",
    "def theta_prior(theta, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on theta. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: scalar value in Reals;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of theta.\"\"\"\n",
    "    \n",
    "    p = stats.norm.pdf(theta, mu_0, sigma_0)\n",
    "    \n",
    "    if debug:\n",
    "        assert 0 < p < 1, \"p not in right range: {}\".format(p)\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    if printing:\n",
    "        print(\"in theta prior\")\n",
    "        print_fn([\"theta\", theta, \"mu_0\", mu_0, sigma_0, \"sigma_0\"])\n",
    "    return p\n",
    "\n",
    "def thetas_log_prior(thetas, shift, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all thetas. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    thetas: vector of scalar value in Reals corresponding to thetas;\n",
    "    shift: value to shift prior means by; scalar value in Reals;\n",
    "    sigma_0: prior standard devation for all thetas; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of thetas.\"\"\"\n",
    "    \n",
    "    k = len(thetas) - 2 # thetas have endpoints of -inf and inf\n",
    "    thetaPriors = []\n",
    "    ks = []\n",
    "    \n",
    "    \n",
    "    for k in np.arange(1,k+1): # ignore first and last value, as these aren't really variables\n",
    "        ks.append(k+shift)\n",
    "        thetaPriors.append(theta_prior(thetas[k], k+shift, sigma_0, printing, debug))\n",
    "    LP = np.sum(np.log(thetaPriors))\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        test = np.append(thetas[1:], 1) - thetas < 0\n",
    "        if test[:-1].any():\n",
    "            print(\"some thetas out of order: {}; test: {}\".format(thetas, test))\n",
    "    if printing:\n",
    "            print_fn([\"sigma_0\", sigma_0])\n",
    "            print_fn([\"ks plus shift\", ks])\n",
    "            print_fn([\"thetas\", thetas])\n",
    "            print_fn([\"thetaPriors\", thetaPriors])\n",
    "            print_fn([\"theta log prior internal\", LP])\n",
    "    return LP\n",
    "\n",
    "def theta_proposal(theta, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual theta. \n",
    "    Simple random walk that reflects on both sides of interval.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: latent threshold; scalar value in (lower_0, upper_0); typically (0, k)\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: lower end of range;\n",
    "    upper_0: upper end of range; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    theta_star: new proposed value for theta.\"\"\"\n",
    "    \n",
    "    theta_star = stats.truncnorm.rvs(lower_0, upper_0, theta, sigma_prop)\n",
    "    if debug:\n",
    "        assert lower_0 <= theta_star <= upper_0\n",
    "    return sigma_star\n",
    "\n",
    "def theta_proposal_prob(theta_new, theta_old, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis-Hastings sampler to evaluate proposal for individual theta. \n",
    "    Simple random walk that reflects on both sides of interval. Note, have to convert lower and upper\n",
    "    to standard normal form; scipy then reconverts based on scale and location parameters.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta_old: latent threshold; scalar value in (lower_0, upper_0); typically (0, k)\n",
    "    theta_new: latent threshold; scalar value in (lower_0, upper_0); typically (0, k)\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: probability for value of theta.\"\"\"\n",
    "    a = (lower_0 - theta_old)/sigma_prop\n",
    "    b = (upper_0 - theta_old)/sigma_prop\n",
    "    p = stats.truncnorm.pdf(theta_new, a, b, theta_old, sigma_prop)\n",
    "    if debug:\n",
    "        assert 0 <= p <= 1, \"p not in right range: {}\".format(p)\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "    \n",
    "\n",
    "def theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"If using truncated normal, no longer symmetric. This is now Metropolis-Hastings algorithm, \n",
    "    and we have to add log of ratio of proposal probabilities to log of acceptance probabilities.\n",
    "    \n",
    "        Inputs\n",
    "    -------------------\n",
    "    theta: latent threshold; scalar value in (lower_0, upper_0); typically (0, k)\n",
    "    theta_star: latent threshold proposal; scalar value in (lower_0, upper_0); typically (0, k)\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: lower end of uniform;\n",
    "    upper_0: upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log probability of ratio of jump probabilities.\"\"\"\n",
    "    # first argument is new proposal\n",
    "    first_term = theta_proposal_prob(theta, theta_star, sigma_prop, \n",
    "                                    lower_0, upper_0, printing, debug)\n",
    "    second_term = theta_proposal_prob(theta_star, theta, sigma_prop, \n",
    "                                      lower_0, upper_0, printing, debug)\n",
    "    LP = np.log(first_term) - np.log(second_term)\n",
    "    \n",
    "#     if printing:\n",
    "#         print(\"First theta log jump probs is {}; second is {}; log diff is {}\".format(first_term, \n",
    "#                                                                                       second_term, LP))\n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        \n",
    "    return LP\n",
    "\n",
    "class ProbabilityFunctionsTestSuite(unittest.TestCase):\n",
    "    \n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def test_mu_prior(self):\n",
    "        \"\"\"Test mu_prior\"\"\"\n",
    "        testValues = [0, 0, 1]\n",
    "        returned_p = mu_prior(*testValues, printing=True, debug=True)\n",
    "        real_p = self.gauss(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_mus_log_prior(self):\n",
    "        \"\"\"Test mus_log_prior\"\"\"\n",
    "        testValues = [[0, 1], 0, 1]\n",
    "        returned_LP = mus_log_prior(*testValues, printing=True, debug=True)\n",
    "        probs = [self.gauss(x, testValues[1], testValues[2]) for x in testValues[0]]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_sigma_prior(self):\n",
    "        \"\"\"Test sigma_prior\"\"\"\n",
    "        testValues = [1, 0, 2]\n",
    "        returned_p = sigma_prior(*testValues, printing=True, debug=True)\n",
    "        real_p = 1/(testValues[-1] - testValues[-2])\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "        testValues = [0, 1, 2]\n",
    "        returned_p = sigma_prior(*testValues, printing=True, debug=True)\n",
    "        real_p = 0.0\n",
    "        self.assertEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_sigmas_log_prior(self):\n",
    "        \"\"\"Test sigmas_log_prior\"\"\"\n",
    "        testValues = [[1, 0], 0.5, 1.5]\n",
    "        returned_LP = sigmas_log_prior(*testValues, printing=True, debug=True)\n",
    "        probs = [1/(testValues[-1]-testValues[-2]) if testValues[1] <= x <= testValues[2] else 0.0 for x in testValues[0] ]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_sigma_proposal_prob(self):\n",
    "        \"\"\"Test sigma_proposal_prob; https://en.wikipedia.org/wiki/Truncated_normal_distribution\"\"\"\n",
    "        testValues = [1, 2, 1, 0, 3]\n",
    "        returned_p = sigma_proposal_prob(*testValues, printing=True, debug=True)\n",
    "        real_p = self.gauss_trunc(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_sigma_log_jump_probs(self):\n",
    "        testValues1 = [1, 2, 1, 0, 3]\n",
    "        testValues2 = [2, 1, 1, 0, 3]\n",
    "        returned_LP = sigma_log_jump_probs(*testValues1, printing=False, debug=False)\n",
    "        real_LP = np.log(self.gauss_trunc(*testValues2)) - np.log(self.gauss_trunc(*testValues1))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_theta_prior(self):\n",
    "        \"\"\"Test theta_prior\"\"\"\n",
    "        testValues = [0, 0, 1]\n",
    "        returned_p = theta_prior(*testValues, printing=True, debug=True)\n",
    "        real_p = self.gauss(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_thetas_log_prior(self):\n",
    "        \"\"\"Test thetas_log_prior\"\"\"\n",
    "        testValues = [[-np.inf, 1.5, 2.5, 3.5, np.inf], 0.5, 1.0]\n",
    "        returned_LP = thetas_log_prior(*testValues, printing=False, debug=False)\n",
    "        probs = [self.gauss(x, i+1.5, 1) for (i, x) in enumerate([1.5, 2.5, 3.5])]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_theta_proposal_prob(self):\n",
    "        \"\"\"Test theta_proposal_prob; https://en.wikipedia.org/wiki/Truncated_normal_distribution\"\"\"\n",
    "        testValues = [1, 2, 1, 0, 3]\n",
    "        returned_p = theta_proposal_prob(*testValues, printing=True, debug=True)\n",
    "        real_p = self.gauss_trunc(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_theta_log_jump_probs(self):\n",
    "        testValues1 = [1, 2, 1, 0, 3]\n",
    "        testValues2 = [2, 1, 1, 0, 3]\n",
    "        returned_LP = theta_log_jump_probs(*testValues1, printing=False, debug=False)\n",
    "        real_LP = np.log(self.gauss_trunc(*testValues2)) - np.log(self.gauss_trunc(*testValues1))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(ProbabilityFunctionsTestSuite))\n",
    "### add test for above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9290fcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
