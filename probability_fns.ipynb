{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8091cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "from math import gamma as gamma_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a2ece",
   "metadata": {},
   "source": [
    "## Probability functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the basic probabilty functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. It draws on helper_fns. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c29955d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=11 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_prior(mu, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on mu using scipy. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in positive Reals;\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of mu. Can be greater than 1, as it is a density.\"\"\"\n",
    "    \n",
    "    p = stats.norm.pdf(mu, mu_0, sigma_0)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "def mus_log_prior(mus, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all mus. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mus: vector of scalar value in Reals corresponding to mus;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation for all mus; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of mus.\"\"\"\n",
    "    \n",
    "    LP = 0 # log prior\n",
    "    \n",
    "    for mu in mus: \n",
    "        LP += np.log(mu_prior(mu, mu_0, sigma_0, printing, debug))\n",
    "        \n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "            \n",
    "    return LP\n",
    "\n",
    "def mu_proposal(mu, sigma_prop, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual mu. \n",
    "    Simple random walk. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma_prop: standard deviation of jumps;  scalar value in positive Reals.\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    mu_star: new proposed value for mu.\"\"\"\n",
    "    \n",
    "    mu_star = np.random.normal(mu, sigma_prop)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(mu_star, float) is True, \"type of LP is not scalar: {}\".format(type(mu_star))\n",
    "        \n",
    "    return mu_star\n",
    "\n",
    "def mu_log_jump_probs(mu, mu_star, sigma_prop, printing=False, debug=False):\n",
    "    \"\"\"While using a symmetric (i.e., non-truncated) proposal, this is merely\"\"\"\n",
    "    return 0 \n",
    "\n",
    "def convert_gamma_parameters(gamma_mean, gamma_spread, printing=False, debug=False):\n",
    "    \"\"\"Helper function for dealing with gamma distribution, prior for sigma.\n",
    "    This is mainly necessary because of scipy. \n",
    "    \n",
    "    N.B., I have used the mean rather than the mode to calculate alpha and beta, because of ease.\n",
    "    \n",
    "    Input\n",
    "    ------------\n",
    "    gamma_mean: float, mean of gamma prior for sigma;\n",
    "    gamma_spread: float from positive Reals, sd of gamma prior for sigma; \n",
    "    \n",
    "    Function\n",
    "    -------------\n",
    "    Use mean and spread to derive alpha and beta for gamma prior, and then use\n",
    "    frequentist parameterization. \n",
    "    \n",
    "    Output\n",
    "    ------------\n",
    "    alpha and scale parameter for gamma prior. \"\"\"\n",
    "    alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "    beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "    scale = 1/beta # as scipy uses frequentist setup\n",
    "    \n",
    "    return alpha, scale\n",
    "\n",
    "def sigma_prior(sigma, gamma_mean, gamma_spread, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on sigma. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: scalar value in positive Reals;\n",
    "    gamma_mean: float, mean of gamma prior for sigma;\n",
    "    gamma_spread: float from positive Reals, sd of gamma prior for sigma; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of sigma. Can be greater than 1, as we are using density.\"\"\"\n",
    "    alpha, scale = convert_gamma_parameters(gamma_mean, gamma_spread)\n",
    "    p = stats.gamma.pdf(sigma, alpha, scale=scale) # I think this is right; loc not needed here\n",
    "    if printing:\n",
    "        print_fn(['sigma', sigma, 'gamma_mean', gamma_mean, 'gamma_spread', gamma_spread, \n",
    "                  'alpha', alpha, 'scale', scale,\n",
    "                 'p', p])\n",
    "    if debug:\n",
    "        assert sigma > 0, \" sigma is negative: {}\".format(sigma) \n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "def sigmas_log_prior(sigmas, gamma_mean, gamma_spread, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all sigmas. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigmas: vector of scalar values in positive Reals, representing standard deviations\n",
    "         of different questions (indexed by q);\n",
    "    gamma_mean: scalar, mean of gamma prior for sigma;\n",
    "    gamma_spread: scalar from positive Reals, sd of gamma prior for sigma; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of sigmas.\"\"\"\n",
    "    \n",
    "    probs = [] # log prior\n",
    "    \n",
    "    for sigma in sigmas: # ignore first and last value, as these aren't really variables\n",
    "        probs.append(sigma_prior(sigma, gamma_mean, gamma_spread, printing, debug))\n",
    "    LP = np.sum(np.log(probs))\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LP, float), \"type of LP is not scalar: {}\".format(type(LP))\n",
    "    if printing:\n",
    "        print_fn(['sigmas', sigmas, 'gamma_mean', gamma_mean, 'gamma_spread', gamma_spread, \n",
    "                 'probs', probs, 'LP', LP])\n",
    "    return LP\n",
    "\n",
    "# change to truncated Gaussian with large upper bound\n",
    "def sigma_proposal(sigma, sigma_prop, lower_sigma, upper_sigma, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual sigma. \n",
    "    Simple random walk that reflects onto non-negatives using truncated Gaussian.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: current latent standard deviation; scalar value in (0, inf); used as mean for new distribution\n",
    "    sigma_prop: scale of jumps; scalar in positive reals;\n",
    "    lower_0: lower end of truncated Gaussian; set to 0 which should never actually occur\n",
    "    upper_0: upper end of truncated Gaussian; set to a high number.\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    sigma_star: new proposed value for sigma.\"\"\"\n",
    "    \n",
    "    a = (lower_sigma - sigma)/sigma_prop\n",
    "    b = (upper_sigma - sigma)/sigma_prop\n",
    "    sigma_star = stats.truncnorm.rvs(a, b, sigma, sigma_prop)\n",
    "    if debug:\n",
    "        assert lower_sigma <= sigma_star <= upper_sigma, \"sigma proposal out: {} < {} < {}; sigma was {}\".format(lower_0, sigma_star, upper_0, sigma)\n",
    "    return sigma_star\n",
    "\n",
    "# needs work\n",
    "def sigma_proposal_prob(sigma_new, sigma_old, sigma_prop, lower_sigma, upper_sigma, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis-Hastings sampler to evaluate proposal for individual sigma. \n",
    "    Simple random walk that reflects on both sides of interval. \n",
    "    \n",
    "    Note, have to convert lower and upper to standard truncated normal form; \n",
    "    scipy then reconverts based on scale parameters.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma_new: scalar in positive Reals; proposed value for sigma\n",
    "    sigma_old: scalar in positive Reals; previous value for sigma\n",
    "    sigma_prop: scale of jumps; \n",
    "    lower_0: scalar in positive Reals; lower limit of trunc proposal dist;\n",
    "    upper_0: scalar in positive reals; upper limit of trunc proposal dist;\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: probability for jump between sigma_old and sigma_new, to be used in acceptance ratio.\"\"\"\n",
    "    \n",
    "    a = (lower_sigma - sigma_old)/sigma_prop\n",
    "    b = (upper_sigma - sigma_old)/sigma_prop\n",
    "    p = stats.truncnorm.pdf(sigma_new, a, b, sigma_old, sigma_prop)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "\n",
    "# arguments need updating\n",
    "def sigma_log_jump_probs(sigma, sigma_star, sigma_prop, lower_sigma, upper_sigma, printing=False, debug=False):\n",
    "    \"\"\"If using truncated normal, no longer symmetric. This is now Metropolis-Hastings algorithm, \n",
    "    and we have to add log of ratio of proposal probabilities to log of acceptance probabilities.\n",
    "    \n",
    "        Inputs\n",
    "    -------------------\n",
    "    sigma: latent standard deviation; scalar value in (lower, upper);\n",
    "    sigma_star: proposed value for latent standard deviation; scalar value in (lower, upper);\n",
    "    sigma_prop: scalar from positive Reals, sd of trunc gauss proposal jump for sigma;\n",
    "    lower_0: scalar from positive Reals; lower limit of trunc proposal dist;\n",
    "    upper_0: scalar from positive Reals; upper limit of trunc proposal dist;\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log probability of ratio of jump probabilities.\"\"\"\n",
    "    \n",
    "    # first argument is proposal, second mean\n",
    "    term_1 = np.log(sigma_proposal_prob(sigma, sigma_star, \n",
    "                                    sigma_prop, lower_sigma, upper_sigma, printing=printing, debug=debug))\n",
    "    term_2 = np.log(sigma_proposal_prob(sigma_star, sigma, \n",
    "                                        sigma_prop, lower_sigma, upper_sigma, printing=printing, debug=debug))\n",
    "\n",
    "    LP =  term_1 - term_2 \n",
    "    if printing:\n",
    "        print_fn(['sigma log jump probs term 1', term_1, 'term_2', term_2])\n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        \n",
    "    return LP\n",
    "\n",
    "def theta_prior(theta, mu_0, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Wrapper for prior on theta. Distribution and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: scalar value in Reals;\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: scalar value in positive Reals; prior standard devation; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: prior probability of the input value of theta. Can be greater than 1 as density.\"\"\"\n",
    "    \n",
    "    p = stats.norm.pdf(theta, mu_0, sigma_0)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    if printing:\n",
    "        print(\"in theta prior\")\n",
    "        print_fn([\"theta\", theta, \"mu_0\", mu_0, sigma_0, \"sigma_0\"])\n",
    "    return p\n",
    "\n",
    "def thetas_log_prior(thetas, shift, sigma_0, printing=False, debug=False):\n",
    "    \"\"\"Returns log prior over all thetas. \n",
    "    Procedure, distributions and hyperparameters taken from original paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    thetas: vector of scalar value in Reals corresponding to thetas;\n",
    "    shift: value to shift prior means by; scalar value in Reals;\n",
    "    sigma_0: prior standard devation for all thetas; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log prior probability of the input value of thetas.\"\"\"\n",
    "    \n",
    "    k = len(thetas) - 2 # thetas have endpoints of -inf and inf\n",
    "    thetaPriors = []\n",
    "    ks = []\n",
    "    \n",
    "    \n",
    "    for k in np.arange(1,k+1): # ignore first and last value, as these aren't really variables\n",
    "        ks.append(k+shift)\n",
    "        thetaPriors.append(theta_prior(thetas[k], k+shift, sigma_0, printing, debug))\n",
    "    LP = np.sum(np.log(thetaPriors))\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        test = np.append(thetas[1:], 1) - thetas < 0\n",
    "        if test[:-1].any():\n",
    "            print(\"some thetas out of order: {}; test: {}\".format(thetas, test))\n",
    "    if printing:\n",
    "            print_fn([\"sigma_0\", sigma_0])\n",
    "            print_fn([\"ks plus shift\", ks])\n",
    "            print_fn([\"thetas\", thetas])\n",
    "            print_fn([\"thetaPriors\", thetaPriors])\n",
    "            print_fn([\"theta log prior internal\", LP])\n",
    "    return LP\n",
    "\n",
    "def theta_proposal(theta, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis sampler to generate proposal for individual theta. \n",
    "    Simple random walk that reflects on both sides of interval. Note, have to convert lower and upper\n",
    "    to standard normal form; scipy then reconverts based on scale and location parameters.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: latent threshold; scalar value in (lower_0, upper_0); typically (1.5, k-0.5)\n",
    "    sigma_prop: scalar value in positive Reals; scale of jumps; \n",
    "    lower_0: scalar value in positive Reals; lower end of range;\n",
    "    upper_0: scalar value in positive Reals; upper end of range; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    theta_star: new proposed value for theta.\"\"\"\n",
    "    \n",
    "    a = (lower_0 - theta)/sigma_prop\n",
    "    b = (upper_0 - theta)/sigma_prop\n",
    "    theta_star = stats.truncnorm.rvs(a, b, theta, sigma_prop)\n",
    "    if debug:\n",
    "        assert lower_0 <= theta_star <= upper_0, \"theta proposal out: {} < {} < {}; theta was {}\".format(lower_0, theta_star, upper_0, theta)\n",
    "    return theta_star\n",
    "\n",
    "def theta_proposal_prob(theta_new, theta_old, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Function for Metropolis-Hastings sampler to evaluate proposal for individual theta. \n",
    "    Simple random walk that reflects on both sides of interval. Note, have to convert lower and upper\n",
    "    to standard normal form; scipy then reconverts based on scale and location parameters.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta_old: latent threshold; scalar value in (lower_0, upper_0); typically (1.5, k-0.5)\n",
    "    theta_new: latent threshold; scalar value in (lower_0, upper_0); typically (1.5, k-0.5)\n",
    "    sigma_prop: scalar value in positive Reals;scale of jumps; \n",
    "    lower_0: scalar value in positive Reals; lower end of uniform;\n",
    "    upper_0: scalar value in positive Reals; upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    p: probability for value of theta.\"\"\"\n",
    "    a = (lower_0 - theta_old)/sigma_prop\n",
    "    b = (upper_0 - theta_old)/sigma_prop\n",
    "    p = stats.truncnorm.pdf(theta_new, a, b, theta_old, sigma_prop)\n",
    "    if debug:\n",
    "        assert isinstance(p, float) is True, \"type of p is not scalar: {}\".format(type(p))\n",
    "    return p\n",
    "    \n",
    "\n",
    "def theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"If using truncated normal, no longer symmetric. This is now Metropolis-Hastings algorithm, \n",
    "    and we have to add log of ratio of proposal probabilities to log of acceptance probabilities.\n",
    "    \n",
    "        Inputs\n",
    "    -------------------\n",
    "    theta: latent threshold; scalar value in (lower_0, upper_0); typically (1.5, k-0.5)\n",
    "    theta_star: latent threshold proposal; scalar value in (lower_0, upper_0); typically (1.5, k-0.5)\n",
    "    sigma_prop: scalar value in positive Reals; scale of jumps; \n",
    "    lower_0: scalar value in positive Reals; lower end of uniform;\n",
    "    upper_0: scalar value in positive Reals; upper end of uniform; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LP: log probability of ratio of jump probabilities.\"\"\"\n",
    "    \n",
    "    # first argument is new proposal\n",
    "    first_term = theta_proposal_prob(theta, theta_star, sigma_prop, \n",
    "                                    lower_0, upper_0, printing, debug)\n",
    "    second_term = theta_proposal_prob(theta_star, theta, sigma_prop, \n",
    "                                      lower_0, upper_0, printing, debug)\n",
    "    LP = np.log(first_term) - np.log(second_term)\n",
    "    \n",
    "    if printing:\n",
    "        print(\"First theta log jump probs is {}; second is {}; log diff is {}\".format(first_term, \n",
    "                                                                                      second_term, LP))\n",
    "    if debug:\n",
    "        assert isinstance(LP, float) is True, \"type of LP is not scalar: {}\".format(type(LP))\n",
    "        \n",
    "    return LP\n",
    "\n",
    "class ProbabilityFunctionsTestSuite(unittest.TestCase):\n",
    "    \"\"\"This is a testing suite for the above functions. Usually only one hand-worked test\n",
    "    per function. All working fine at time of build. \n",
    "    \n",
    "    Any modification to one of these function's inputs, function, or output will require\n",
    "    a modification to the corresponding example. If so, turn printing and debug on to work through.\n",
    "    \"\"\"\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def gamma(self, x, gamma_mean, gamma_spread, printing=False):\n",
    "        \"\"\"Return probability under gamma distribution.\"\"\"\n",
    "        alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "        beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "        \n",
    "        term_1 = (beta**alpha)\n",
    "        term_2 = 1/gamma_fn(alpha)\n",
    " \n",
    "        term_3 = (x**(alpha-1)) \n",
    "        term_4 = np.exp(-beta*x)\n",
    "        if printing:\n",
    "            print('exterior alpha, beta', alpha, beta)\n",
    "        #print_fn([\"term_1\", term_1, \"term_2\", term_2, \"term_3\", term_3, \"term_4\", term_4])\n",
    "        return term_1*term_2*term_3*term_4\n",
    "    \n",
    "    def test_mu_prior(self):\n",
    "        \"\"\"Test mu_prior\"\"\"\n",
    "        testValues = [0, 0, 1]\n",
    "        returned_p = mu_prior(*testValues, printing=False, debug=True)\n",
    "        real_p = self.gauss(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_mus_log_prior(self):\n",
    "        \"\"\"Test mus_log_prior\"\"\"\n",
    "        testValues = [[0, 1], 0, 1]\n",
    "        returned_LP = mus_log_prior(*testValues, printing=False, debug=True)\n",
    "        probs = [self.gauss(x, testValues[1], testValues[2]) for x in testValues[0]]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    # this will need changing\n",
    "    def test_sigma_prior(self):\n",
    "        \"\"\"Test sigma_prior\"\"\"\n",
    "        testValues = [1.0, 2.0, 2.0]\n",
    "        real_p = self.gamma(*testValues, printing=False)\n",
    "        returned_p = sigma_prior(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        mean = 2.0\n",
    "        sd = 3.0\n",
    "        testValues2 = [0.1, mean, sd]\n",
    "        real_p = self.gamma(*testValues2, printing=False)\n",
    "        returned_p = sigma_prior(*testValues2, printing=False, debug=True)\n",
    "        \n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    # this will need changing\n",
    "    def test_sigmas_log_prior(self):\n",
    "        \"\"\"Test sigmas_log_prior\"\"\"\n",
    "        testValues = [[1, 0.2], 0.5, 1.5]\n",
    "        returned_LP = sigmas_log_prior(*testValues, printing=False, debug=True)\n",
    "\n",
    "        probs = [self.gamma(x, 0.5, 1.5) for x in testValues[0]]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    \n",
    "    def test_scipy_gamma(self):\n",
    "        \"\"\"alpha and beta (rate) are Bayesian way of parameterizing.\"\"\"\n",
    "        alpha = 2\n",
    "        beta = 2\n",
    "        mean = alpha/beta\n",
    "        sd = np.sqrt(alpha)/beta\n",
    "        alpha, inv_beta = convert_gamma_parameters(mean, sd, debug=True)\n",
    "        p = stats.gamma.pdf(mean, alpha, scale=inv_beta)\n",
    "        gamma_p = self.gamma(mean, mean, sd)\n",
    "        self.assertAlmostEqual(p, gamma_p)\n",
    "        \n",
    "        \n",
    "    def test_sigma_proposal_prob(self):\n",
    "        \"\"\"Test sigma_proposal_prob; https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.gamma.html;\"\"\"\n",
    "        testValues = [1, 2, 3.0, 0, 100] # proposal, old, gamma_spread\n",
    "        returned_p = sigma_proposal_prob(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        # this will not be true\n",
    "        real_p = self.gauss_trunc(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    # this will need changing\n",
    "    def test_sigma_log_jump_probs(self):\n",
    "        testValues1 = [1, 2, 3.0, 0, 100]\n",
    "        testValues2 = [2, 1, 3.0, 0, 100]\n",
    "        returned_LP = sigma_log_jump_probs(*testValues1, printing=False, debug=True)\n",
    "        \n",
    "        real_LP = np.log(self.gauss_trunc(*testValues1)) - np.log(self.gauss_trunc(*testValues2)) \n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_theta_prior(self):\n",
    "        \"\"\"Test theta_prior\"\"\"\n",
    "        testValues = [0, 0, 1]\n",
    "        returned_p = theta_prior(*testValues, printing=False, debug=True)\n",
    "        real_p = self.gauss(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_thetas_log_prior(self):\n",
    "        \"\"\"Test thetas_log_prior\"\"\"\n",
    "        testValues = [[-np.inf, 1.5, 2.5, 3.5, np.inf], 0.5, 1.0]\n",
    "        returned_LP = thetas_log_prior(*testValues, printing=False, debug=False)\n",
    "        probs = [self.gauss(x, i+1.5, 1) for (i, x) in enumerate([1.5, 2.5, 3.5])]\n",
    "        real_LP = np.sum(np.log(probs))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_theta_proposal_prob(self):\n",
    "        \"\"\"Test theta_proposal_prob; https://en.wikipedia.org/wiki/Truncated_normal_distribution\"\"\"\n",
    "        testValues = [1, 2, 1, 0, 3]\n",
    "        returned_p = theta_proposal_prob(*testValues, printing=False, debug=True)\n",
    "        real_p = self.gauss_trunc(*testValues)\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_theta_log_jump_probs(self):\n",
    "        testValues1 = [1, 2, 1, 0, 3]\n",
    "        testValues2 = [2, 1, 1, 0, 3]\n",
    "        returned_LP = theta_log_jump_probs(*testValues1, printing=False, debug=False)\n",
    "        real_LP = np.log(self.gauss_trunc(*testValues2)) - np.log(self.gauss_trunc(*testValues1))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(ProbabilityFunctionsTestSuite))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
