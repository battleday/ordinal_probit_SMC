{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44459/1777929584.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44459/1777929584.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP = np.sum(np.log(probs))\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "%run helper_fns.ipynb\n",
    "%run probability_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 guessVector [1, 2] mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 1\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.6914624612740131 LOP 0.6914624612740131\n",
      "y is 2\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.6914624612740131 end 0.9331927987311419 LOP 0.2417303374571288\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, -1.0, 0.0, 1.0, inf]\n",
      "start 0.0 end 0.022750131948179195 LOP 0.022750131948179195\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 0.0, -1.0, 1.0, inf]\n",
      "start 0.15865525393145707 end 0.022750131948179195 LOP 0\n",
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf] l1 0 l2 3\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 guessVector [1, 2] mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 1\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.6914624612740131 LOP 0.6914624612740131\n",
      "y is 2\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.6914624612740131 end 0.9331927987311419 LOP 0.2417303374571288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LOP(y, mu, sigma, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns likelihood given by ordinal probit model for a particular guess.\n",
    "    Inputs\n",
    "    -------------------\n",
    "    y: single guess. Should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LOP: likelihood; scalar in (0, 1).\n",
    "    \"\"\"\n",
    "    start = stats.norm.cdf(thetas[y-1], mu, sigma)\n",
    "    end = stats.norm.cdf(thetas[y], mu, sigma)\n",
    "    LOP = max(0, end-start)\n",
    "    if debug:\n",
    "        assert isinstance(y, int), \"y is not int: {}\".format(y)\n",
    "        assert isinstance(mu, float), \"mu is not scalar: {}\".format(mu)\n",
    "        assert isinstance(sigma, float), \"sigma is not scalar: {}\".format(sigma)\n",
    "        assert y in np.arange(1, len(thetas)-1), \"y is out of range: {}; thetas: {}\".format(y, thetas)\n",
    "        assert 0.0 <= start <= 1.0, \"start not in right range: {} vs [0, 1]\".format(start)\n",
    "        assert 0.0 <= end <= 1.0, \"end not in right range: {} vs [0, 1]\".format(end)\n",
    "        if end-start < 0:\n",
    "            print(\"end is lower than start; can happen and will return 0 which will cause neg infs later: {}\".format(thetas))\n",
    "        \n",
    "    return LOP\n",
    "    \n",
    "def LLQ(guessVector, mu, sigma, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns log likelihood for a single question / survey item under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LLQ: log likelihood; scalar in (-inf, 0).\"\"\"\n",
    "    LLQ = 0\n",
    "    for y in guessVector:\n",
    "        LLQ += np.log(LOP(y, mu, sigma, thetas))\n",
    "    \n",
    "    if debug:\n",
    "        assert all(isinstance(x, int) for x in guessVector), \"guessVector not ints: {}\".format(guessVector)\n",
    "        \n",
    "    return LLQ\n",
    "        \n",
    "def LL(guessMatrix, mus, sigmas, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns log likelihood for all questions / survey items under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessMatrix: guesses / y's. Each should be an integer from 1:k; could be list of lists or matrix of ints;\n",
    "    mus: latent means for all question; scalar vector in Reals;\n",
    "    sigmas: latent sds for all questions; scalar vector in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5], assuming \n",
    "        k invariant between questions\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LL: log likelihood; scalar in (-inf, 0).\"\"\"\n",
    "    LL = 0\n",
    "    for c, guessVector in enumerate(guessMatrix):\n",
    "        LL += LLQ(guessVector, mus[c], sigmas[c], thetas, printing, debug)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        \n",
    "    return LL\n",
    "\n",
    "\n",
    "        \n",
    "def joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for a single mu (question) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "   \n",
    "    \"\"\"\n",
    "    LL = LLQ(guessVector, mu, sigma, thetas, printing, debug)\n",
    "    LP = np.log(mu_prior(mu, mu_0, sigma_0, printing, debug))\n",
    "    LJ = LL + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        if LL + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(LL))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "            \n",
    "    return LJ\n",
    "\n",
    "def joint_log_probability_sigma(guessVector, mu, sigma, thetas, lower_0, upper_0, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for a single sigma (question) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "    \n",
    "    lower_0, upper_0\n",
    "   \n",
    "    \"\"\"\n",
    "    LL = LLQ(guessVector, mu, sigma, thetas, printing, debug)\n",
    "    LP = np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
    "    LJ = LL + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        if LL + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(LL))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "    return LJ\n",
    "\n",
    "def joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_0, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for all thetas (all questions) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessMatrix: guesses / y's. Each should be an integer from 1:k; could be list of lists or matrix of ints;\n",
    "    mus: latent means for all question; scalar vector in Reals;\n",
    "    sigmas: latent sds for all questions; scalar vector in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5], assuming \n",
    "        k invariant between questions\n",
    "    shift: to add to prior means to help with intervals; pretty much always 0.5; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "   \n",
    "    \"\"\"\n",
    "    L = LL(guessMatrix, mus, sigmas, thetas, printing, debug)\n",
    "    LP = thetas_log_prior(thetas, shift, sigma_0, printing, debug)\n",
    "    LJ = L + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(L, float), \"LL not scalar: {}\".format(L)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= L <= 0, \"LL out of range: {}\".format(L)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        \n",
    "        if L + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(L))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "            \n",
    "    if printing:\n",
    "        print_fn([\"thetas\", thetas, \"shift\", shift, \"sigma_0\", sigma_0, \"LP\", LP])\n",
    "    return LJ\n",
    "\n",
    "class LikelihoodFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def test_LOP(self):\n",
    "        testValues1 = [1, 1.0, 1.0, [-np.inf, -1.0, 0.0, 1.0, np.inf]]\n",
    "        returned_p = LOP(*testValues1, printing=True, debug=True)\n",
    "        real_p = max(0, stats.norm.cdf(-1.0, 1, 1) - stats.norm.cdf(-np.inf, 1, 1))\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "        testValues2 = [2, 1.0, 1.0, [-np.inf, 0.0, -1.0, 1.0, np.inf]]\n",
    "        returned_p = LOP(*testValues2, printing=True, debug=True)\n",
    "        real_p = 0\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_LLQ(self):\n",
    "        testValues = [[2, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf]]\n",
    "        returned_LP = LLQ(*testValues, printing=True, debug=True)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0))]))\n",
    "        \n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_LL(self):\n",
    "        testValues = [[[2, 1], [1, 2]], [0.0, 1.0], [2.0, 1.0], [-np.inf, 1.5, 2.5, np.inf]]\n",
    "        returned_LP = LL(*testValues, printing=True, debug=True)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                               max(0, stats.norm.cdf(1.5, 1.0, 1.0) - stats.norm.cdf(-np.inf, 1.0, 1.0)),\n",
    "                               max(0, stats.norm.cdf(2.5, 1.0, 1.0) - stats.norm.cdf(1.5, 1.0, 1.0))]))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_mu(self):\n",
    "        testValues = [[2, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0] \n",
    "        returned_LP = joint_log_probability_mu(*testValues, \n",
    "                        printing=False, debug=False)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                                self.gauss(0.0, 1.0, 1.0)]))\n",
    "        \n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_sigma(self):\n",
    "      \n",
    "        testValues = [[2, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf], 0, 3] \n",
    "        returned_LP = joint_log_probability_sigma(*testValues, \n",
    "                        printing=False, debug=False)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                                1/(3-0)]))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_thetas(self):\n",
    "        testValues = [[[2, 1], [1, 2]], [0.0, 1.0], [2.0, 1.0], [-np.inf, 1.5, 2.5, np.inf], 0.5, 1.0]\n",
    "        returned_LP = joint_log_probability_thetas(*testValues, printing=True, debug=True)\n",
    "        real_LP_1 = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                               max(0, stats.norm.cdf(1.5, 1.0, 1.0) - stats.norm.cdf(-np.inf, 1.0, 1.0)),\n",
    "                               max(0, stats.norm.cdf(2.5, 1.0, 1.0) - stats.norm.cdf(1.5, 1.0, 1.0))]))\n",
    "        real_LP_2 = np.sum(np.log([self.gauss(x, i+1.5, 1) for (i, x) in enumerate([1.5, 2.5])]))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP_1 + real_LP_2)\n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(LikelihoodFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1b89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
