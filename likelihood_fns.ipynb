{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.015s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "import sys\n",
    "%run helper_fns.ipynb\n",
    "%run probability_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.014s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=0 failures=0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LOP(y, mu, sigma, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns likelihood given by ordinal probit model for a particular guess.\n",
    "    Inputs\n",
    "    -------------------\n",
    "    y: single guess. Should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LOP: likelihood; scalar in (0, 1).\n",
    "    \"\"\"\n",
    "    start = stats.norm.cdf(thetas[y-1], mu, sigma)\n",
    "    end = stats.norm.cdf(thetas[y], mu, sigma)\n",
    "    LOP = max(0, end-start)\n",
    "    if debug:\n",
    "        assert isinstance(y, int), \"y is not int: {}\".format(y)\n",
    "        assert isinstance(mu, float), \"mu is not scalar: {}\".format(mu)\n",
    "        assert isinstance(sigma, float), \"sigma is not scalar: {}\".format(sigma)\n",
    "        assert y in np.arange(1, len(thetas)-1), \"y is out of range: {}; thetas: {}\".format(y, thetas)\n",
    "        assert 0.0 <= start <= 1.0, \"start not in right range: {} vs [0, 1]\".format(start)\n",
    "        assert 0.0 <= end <= 1.0, \"end not in right range: {} vs [0, 1]\".format(end)\n",
    "        if end-start < 0:\n",
    "            print(\"end is lower than start; can happen and will return 0 which will cause neg infs later: {}\".format(thetas))\n",
    "        \n",
    "    return LOP\n",
    "    \n",
    "def LLQ(guessVector, mu, sigma, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns log likelihood for a single question / survey item under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: counts of guesses / y's for question. Each should be an integer / count; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LLQ: log likelihood; scalar in (-inf, 0).\"\"\"\n",
    "    LLQ = 0\n",
    "    for ans, counts in enumerate(guessVector):\n",
    "        # guesses are 1-indexed\n",
    "        prob = LOP(ans+1, mu, sigma, thetas)\n",
    "        LLQ += counts * np.log(prob) # this means fewer calls to lookup table\n",
    "    \n",
    "   \n",
    "    return LLQ\n",
    "        \n",
    "def LL(guessMatrix, mus, sigmas, thetas, printing=False, debug=False):\n",
    "    \"\"\"Returns log likelihood for all questions / survey items under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessMatrix: counts of guesses / y's. Each should be an integer / count; could be list of lists or matrix of ints;\n",
    "    mus: latent means for all question; scalar vector in Reals;\n",
    "    sigmas: latent sds for all questions; scalar vector in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5], assuming \n",
    "        k invariant between questions\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LL: log likelihood; scalar in (-inf, 0).\"\"\"\n",
    "    LL = 0\n",
    "    for c, guessVector in enumerate(guessMatrix):\n",
    "        LL += LLQ(guessVector, mus[c], sigmas[c], thetas, printing, debug)\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        \n",
    "    return LL\n",
    "\n",
    "\n",
    "        \n",
    "def joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for a single mu (question) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "   \n",
    "    \"\"\"\n",
    "    LL = LLQ(guessVector, mu, sigma, thetas, printing, debug)\n",
    "    LP = np.log(mu_prior(mu, mu_0, sigma_0, printing, debug))\n",
    "    LJ = LL + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        if LL + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(LL))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "            \n",
    "    return LJ\n",
    "\n",
    "def joint_log_probability_sigma(guessVector, mu, sigma, thetas, gamma_mean, gamma_spread, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for a single sigma (question) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5]\n",
    "    gamma_mean: prior mean; scalar value in Reals;\n",
    "    gamma_spread: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "    \n",
    "    \"\"\"\n",
    "    LL = LLQ(guessVector, mu, sigma, thetas, printing, debug)\n",
    "    LP = np.log(sigma_prior(sigma, gamma_mean, gamma_spread, printing, debug))\n",
    "    LJ = LL + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(LL, float), \"LL not scalar: {}\".format(LL)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= LL <= 0, \"LL out of range: {}\".format(LL)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        if LL + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(LL))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "    return LJ\n",
    "\n",
    "def joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_0, \n",
    "                        printing=False, debug=False):\n",
    "    \n",
    "    \"\"\"Returns log joint probability for all thetas (all questions) under ordinal probit model. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    guessMatrix: guesses / y's. Each should be an integer from 1:k; could be list of lists or matrix of ints;\n",
    "    mus: latent means for all question; scalar vector in Reals;\n",
    "    sigmas: latent sds for all questions; scalar vector in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5], assuming \n",
    "        k invariant between questions\n",
    "    shift: to add to prior means to help with intervals; pretty much always 0.5; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    LJ: : log joint likelihood; scalar in (-inf, 0).\n",
    "   \n",
    "    \"\"\"\n",
    "    L = LL(guessMatrix, mus, sigmas, thetas, printing, debug)\n",
    "    LP = thetas_log_prior(thetas, shift, sigma_0, printing, debug)\n",
    "    LJ = L + LP\n",
    "    \n",
    "    if debug:\n",
    "        assert isinstance(L, float), \"LL not scalar: {}\".format(L)\n",
    "        assert isinstance(LP, float), \"LP not scalar: {}\".format(LP)\n",
    "        assert -np.inf <= L <= 0, \"LL out of range: {}\".format(L)\n",
    "        assert -np.inf <= LP <= 0, \"LL out of range: {}\".format(LP)\n",
    "        \n",
    "        if L + LP == -np.inf:\n",
    "            print(\"np.inf returned; should only really happen with thetas out of order:{}\".format(thetas))\n",
    "            print(\"LL: {}\".format(L))\n",
    "            print(\"LP: {}\".format(LP))\n",
    "            \n",
    "    if printing:\n",
    "        print_fn([\"thetas\", thetas, \"shift\", shift, \"sigma_0\", sigma_0, \"LP\", LP])\n",
    "    return LJ\n",
    "\n",
    "class LikelihoodFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def gamma(self, x, gamma_mean, gamma_spread, printing=False):\n",
    "        \"\"\"Return probability under gamma distribution.\"\"\"\n",
    "        alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "        beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "        \n",
    "        term_1 = (beta**alpha)\n",
    "        term_2 = 1/gamma_fn(alpha)\n",
    " \n",
    "        term_3 = (x**(alpha-1)) \n",
    "        term_4 = np.exp(-beta*x)\n",
    "        if printing:\n",
    "            print('exterior alpha, beta', alpha, beta)\n",
    "        #print_fn([\"term_1\", term_1, \"term_2\", term_2, \"term_3\", term_3, \"term_4\", term_4])\n",
    "        return term_1*term_2*term_3*term_4\n",
    "    \n",
    "    def test_LOP(self):\n",
    "        testValues1 = [1, 1.0, 1.0, [-np.inf, -1.0, 0.0, 1.0, np.inf]]\n",
    "        returned_p = LOP(*testValues1, printing=False, debug=True)\n",
    "        real_p = max(0, stats.norm.cdf(-1.0, 1, 1) - stats.norm.cdf(-np.inf, 1, 1))\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "        testValues2 = [2, 1.0, 1.0, [-np.inf, 0.0, -1.0, 1.0, np.inf]]\n",
    "        returned_p = LOP(*testValues2, printing=False, debug=True)\n",
    "        real_p = 0\n",
    "        self.assertAlmostEqual(returned_p, real_p)\n",
    "        \n",
    "    def test_LLQ(self):\n",
    "        testValues = [[1, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf]]\n",
    "        returned_LP = LLQ(*testValues, printing=False, debug=True)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0))]))\n",
    "        \n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_LL(self):\n",
    "        testValues = [[[1, 1], [1, 1]], [0.0, 1.0], [2.0, 1.0], [-np.inf, 1.5, 2.5, np.inf]]\n",
    "        returned_LP = LL(*testValues, printing=False, debug=True)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                               max(0, stats.norm.cdf(1.5, 1.0, 1.0) - stats.norm.cdf(-np.inf, 1.0, 1.0)),\n",
    "                               max(0, stats.norm.cdf(2.5, 1.0, 1.0) - stats.norm.cdf(1.5, 1.0, 1.0))]))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_mu(self):\n",
    "        testValues = [[1, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0] \n",
    "        returned_LP = joint_log_probability_mu(*testValues, \n",
    "                        printing=False, debug=False)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                                self.gauss(0.0, 1.0, 1.0)]))\n",
    "        \n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_sigma(self):\n",
    "      \n",
    "        testValues = [[1, 1], 0.0, 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 2.0] \n",
    "        guessVector, mean, sigma, thetas, gamma_mean, gamma_spread = testValues.copy()\n",
    "        returned_LP = joint_log_probability_sigma(*testValues, \n",
    "                        printing=False, debug=False)\n",
    "        real_LP = np.sum(np.log([max(0, stats.norm.cdf(2.5, mean, sigma) - stats.norm.cdf(1.5, mean, sigma)), \n",
    "                                max(0, stats.norm.cdf(1.5, mean, sigma) - stats.norm.cdf(-np.inf, mean, sigma)),\n",
    "                                self.gamma(sigma, gamma_mean, gamma_spread)])) # last argument is summe log prior?\n",
    "        self.assertAlmostEqual(returned_LP, real_LP)\n",
    "        \n",
    "    def test_joint_log_probability_thetas(self):\n",
    "        testValues = [[[1, 1], [1, 1]], [0.0, 1.0], [2.0, 1.0], [-np.inf, 1.5, 2.5, np.inf], 0.5, 1.0]\n",
    "        returned_LP = joint_log_probability_thetas(*testValues, printing=False, debug=True)\n",
    "        real_LP_1 = np.sum(np.log([max(0, stats.norm.cdf(2.5, 0.0, 2.0) - stats.norm.cdf(1.5, 0.0, 2.0)), \n",
    "                                max(0, stats.norm.cdf(1.5, 0.0, 2.0) - stats.norm.cdf(-np.inf, 0.0, 2.0)),\n",
    "                               max(0, stats.norm.cdf(1.5, 1.0, 1.0) - stats.norm.cdf(-np.inf, 1.0, 1.0)),\n",
    "                               max(0, stats.norm.cdf(2.5, 1.0, 1.0) - stats.norm.cdf(1.5, 1.0, 1.0))]))\n",
    "        real_LP_2 = np.sum(np.log([self.gauss(x, i+1.5, 1) for (i, x) in enumerate([1.5, 2.5])]))\n",
    "        self.assertAlmostEqual(returned_LP, real_LP_1 + real_LP_2)\n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(LikelihoodFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1b89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26ca1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9d7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
