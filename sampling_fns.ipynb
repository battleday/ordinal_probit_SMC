{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44478/1777929584.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44478/1777929584.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP = np.sum(np.log(probs))\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.010s\n",
      "\n",
      "OK\n",
      "...../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44478/1777929584.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44478/1777929584.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP = np.sum(np.log(probs))\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.010s\n",
      "\n",
      "OK\n",
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 guessVector [1, 2] mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 1\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.6914624612740131 LOP 0.6914624612740131\n",
      "y is 2\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.6914624612740131 end 0.9331927987311419 LOP 0.2417303374571288\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, -1.0, 0.0, 1.0, inf]\n",
      "start 0.0 end 0.022750131948179195 LOP 0.022750131948179195\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 0.0, -1.0, 1.0, inf]\n",
      "start 0.15865525393145707 end 0.022750131948179195 LOP 0\n",
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf] l1 0 l2 3\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 guessVector [1, 2] mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 1\n",
      "sigma 1.0 y 1 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.6914624612740131 LOP 0.6914624612740131\n",
      "y is 2\n",
      "sigma 1.0 y 2 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.6914624612740131 end 0.9331927987311419 LOP 0.2417303374571288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.020s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "%run probability_fns.ipynb\n",
    "%run likelihood_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04445b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_suite(TestCase):\n",
    "    loader = unittest.TestLoader()\n",
    "    suite = loader.loadTestsFromTestCase(TestCase)\n",
    "    return suite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma 2.0 guessVector [2, 1] mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.5987063256829237 end 0.7733726476231317 LOP 0.17466632194020804\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 1.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.5987063256829237 LOP 0.5987063256829237\n",
      "sigma 2.0 guessVector [2, 1] mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.7733726476231317 end 0.8943502263331446 LOP 0.12097757871001291\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 0.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.7733726476231317 LOP 0.7733726476231317\n",
      "sigma 1.0 sigma_star 2.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf] sj 2.0 l1 0 l2 3\n",
      "sigma 1.0 sigma_star 2.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf] sj 2.0 l1 0 l2 3\n",
      "sigma 2.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf] l1 0 l2 3\n",
      "sigma 2.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 2.0 y 2 mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.4012936743170763 end 0.5987063256829237 LOP 0.1974126513658474\n",
      "y is 1\n",
      "sigma 2.0 y 1 mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.4012936743170763 LOP 0.4012936743170763\n",
      "sigma 1.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf] l1 0 l2 3\n",
      "sigma 1.0 guessVector [2, 1] mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "y is 2\n",
      "sigma 1.0 y 2 mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.3085375387259869 end 0.6914624612740131 LOP 0.38292492254802624\n",
      "y is 1\n",
      "sigma 1.0 y 1 mu 2.0 thetas [-inf, 1.5, 2.5, inf]\n",
      "start 0.0 end 0.3085375387259869 LOP 0.3085375387259869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.014s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_accept(mu, mu_star, guessVector, sigma, thetas, mu_0, sigma_0, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for mu.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: current latent mean; scalar value in Reals;\n",
    "    mu_star: proposal for new latent mean; scalar value in Reals;\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    A1 = joint_log_probability_mu(guessVector, mu_star, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = mu_log_jump_probs(mu, mu_star, sigma_prop, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "def sigma_accept(sigma, sigma_star, guessVector, mu, thetas, sigma_prop, lower_0, upper_0,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for sigma.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: current latent mean; scalar value in (0, inf);\n",
    "    sigma_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent sd; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    A1 = joint_log_probability_sigma(guessVector, mu, sigma_star, thetas, lower_0, upper_0,\n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_sigma(guessVector, mu, sigma, thetas, lower_0, upper_0,\n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = sigma_log_jump_probs(sigma, sigma_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "class LikelihoodFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def test_mu_accept(self):\n",
    "        #             mu. mu_star  y.    sigma         thetas             mu_0 s_0  s_j\n",
    "        testValues = [0.0, 1.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0, 2.0]\n",
    "        mu, mu_star, guessVector, sigma, thetas, mu_0, s_0, s_j = testValues.copy()\n",
    "        \n",
    "        returned_A = mu_accept(*testValues, printing=True, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu_star, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu_star, sigma)),\n",
    "                                self.gauss(mu_star, mu_0, s_0)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                self.gauss(mu, mu_0, s_0)]))\n",
    "        \n",
    "        real_A3 = 0\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        \n",
    "    def test_sigma_accept(self):\n",
    "#         sigma_accept(sigma, sigma_star, guessVector, mu, thetas, mu_0, sigma_0, sigma_prop, lower_0, upper_0,\n",
    "        #             s.  s_star  y.    mu         thetas                s_j l1 l2\n",
    "        testValues = [1.0, 2.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 2.0, 0, 3]\n",
    "        sigma, sigma_star, guessVector, mu, thetas, s_j, l1, l2 = testValues.copy()\n",
    "        returned_A = sigma_accept(*testValues, printing=True, debug=True)\n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma_star)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma_star)),\n",
    "                                1/(l2-l1)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                1/(l2-l1)]))\n",
    "        real_A3 = np.log(self.gauss_trunc(sigma, sigma_star, s_j, l1, l2)) - np.log(self.gauss_trunc(sigma_star, sigma, s_j, l1, l2)) # because symmetric ---> Metropolis\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "    \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(LikelihoodFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6d0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
