{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/906992457.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/906992457.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP = np.sum(np.log(probs))\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.011s\n",
      "\n",
      "OK\n",
      "...../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/906992457.py:117: RuntimeWarning: divide by zero encountered in log\n",
      "  LP += np.log(sigma_prior(sigma, lower_0, upper_0, printing, debug))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/906992457.py:373: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP = np.sum(np.log(probs))\n",
      ".....\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.010s\n",
      "\n",
      "OK\n",
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.012s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "%run probability_fns.ipynb\n",
    "%run likelihood_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04445b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_suite(TestCase):\n",
    "    loader = unittest.TestLoader()\n",
    "    suite = loader.loadTestsFromTestCase(TestCase)\n",
    "    return suite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..F\n",
      "======================================================================\n",
      "FAIL: test_theta_accept (__main__.LikelihoodFunctionsTestSuite)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/1685385032.py\", line 159, in test_theta_accept\n",
      "    returned_A = theta_accept(*testValues, printing=True, debug=True)\n",
      "  File \"/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_44869/1685385032.py\", line 101, in theta_accept\n",
      "    assert -np.inf <= A <= 0.0, \"A not in range: A1 {} A2 {} A3{}\".format(A1, A2, A3)\n",
      "AssertionError: A not in range: A1 -9.024957400482823 A2 -9.004984854591386 A30.02172746830337635\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.009s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=1>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_accept(mu, mu_star, guessVector, sigma, thetas, mu_0, sigma_0, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for mu.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: current latent mean; scalar value in Reals;\n",
    "    mu_star: proposal for new latent mean; scalar value in Reals;\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    A1 = joint_log_probability_mu(guessVector, mu_star, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = mu_log_jump_probs(mu, mu_star, sigma_prop, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "def sigma_accept(sigma, sigma_star, guessVector, mu, thetas, sigma_prop, lower_0, upper_0,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for sigma.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: current latent mean; scalar value in (0, inf);\n",
    "    sigma_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    A1 = joint_log_probability_sigma(guessVector, mu, sigma_star, thetas, lower_0, upper_0,\n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_sigma(guessVector, mu, sigma, thetas, lower_0, upper_0,\n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = sigma_log_jump_probs(sigma, sigma_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "def theta_accept(theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_prop, \n",
    "                 lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for theta. A bit inefficient. Note, have to monitor\n",
    "    here for -infs, as sometimes the proposals reverse order sloppily. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: a current threshold; scalar value in (0, inf);\n",
    "    theta_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "\n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    thetasTemp = thetas.copy()\n",
    "    thetasTemp[center] = theta_star\n",
    "    \n",
    "    A1 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetasTemp, shift, sigma_prop,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A2 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_prop,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A3 = theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "\n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if debug:\n",
    "        assert -np.inf <= A <= 0.0, \"A not in range: A1 {} A2 {} A3{}\".format(A1, A2, A3)\n",
    "        if np.isneginf(A):\n",
    "            print('A is -inf: A1 {} A2 {} A3{}'.format(A1, A2, A3))\n",
    "            \n",
    "    if np.isneginf(A):\n",
    "        return 0.0 # do not move if that would swap a threshold\n",
    "    else:\n",
    "        return min(1, np.exp(A))\n",
    "    \n",
    "class LikelihoodFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def test_mu_accept(self):\n",
    "        #             mu. mu_star  y.    sigma         thetas             mu_0 s_0  s_j\n",
    "        testValues = [0.0, 1.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0, 2.0]\n",
    "        mu, mu_star, guessVector, sigma, thetas, mu_0, s_0, s_j = testValues.copy()\n",
    "        \n",
    "        returned_A = mu_accept(*testValues, printing=True, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu_star, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu_star, sigma)),\n",
    "                                self.gauss(mu_star, mu_0, s_0)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                self.gauss(mu, mu_0, s_0)]))\n",
    "        \n",
    "        real_A3 = 0\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        \n",
    "    def test_sigma_accept(self):\n",
    "        #             s.  s_star  y.    mu         thetas                s_j l1 l2\n",
    "        testValues = [1.0, 2.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 2.0, 0, 3]\n",
    "        sigma, sigma_star, guessVector, mu, thetas, s_j, l1, l2 = testValues.copy()\n",
    "        returned_A = sigma_accept(*testValues, printing=True, debug=True)\n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma_star)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma_star)),\n",
    "                                1/(l2-l1)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                1/(l2-l1)]))\n",
    "        real_A3 = np.log(self.gauss_trunc(sigma, sigma_star, s_j, l1, l2)) - np.log(self.gauss_trunc(sigma_star, sigma, s_j, l1, l2)) # because symmetric ---> Metropolis\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "    def test_theta_accept(self):\n",
    "        testValues = [2.5, 2.6, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[2, 1], [2, 3]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 2.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_prop, lower_0, upper_0 = testValues.copy()\n",
    "        returned_A = theta_accept(*testValues, printing=True, debug=True)\n",
    "    \n",
    "    \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(LikelihoodFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c54da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
