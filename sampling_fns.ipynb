{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.011s\n",
      "\n",
      "OK\n",
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.010s\n",
      "\n",
      "OK\n",
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "import sys\n",
    "%run helper_fns.ipynb\n",
    "%run probability_fns.ipynb\n",
    "%run likelihood_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_75349/1839039262.py:51: RuntimeWarning: divide by zero encountered in log\n",
      "  LLQ += counts * np.log(prob) # this means fewer calls to lookup table\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_75349/110277214.py:253: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP_1 = np.sum(np.log([max(0,\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some thetas out of order: [-inf, 1.5, 1.3, 3.5, inf]; test: [False  True False False  True]\n",
      "np.inf returned; should only really happen with thetas out of order:[-inf, 1.5, 1.3, 3.5, inf]\n",
      "LL: -inf\n",
      "LP: -3.4768155996140178\n",
      "A is -inf: A -inf; A1 -inf A2 -6.92554331291155 A3 -0.2255550003176261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_accept(mu, mu_star, guessVector, sigma, thetas, mu_0, sigma_0, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for mu.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: current latent mean; scalar value in Reals;\n",
    "    mu_star: proposal for new latent mean; scalar value in Reals;\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    A1 = joint_log_probability_mu(guessVector, mu_star, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = mu_log_jump_probs(mu, mu_star, sigma_prop, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "#     if debug:\n",
    "#         if A <= np.log(sys.float_info.max):\n",
    "#             print(\"A will cause overflow:\\\n",
    "#         {} (A1) {} (A2) {} (A3) {}\".format(A, A1, A2, A3))\n",
    "\n",
    "    if A > 0: # if more probably (in log space), always jump\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(A)\n",
    "\n",
    "def sigma_accept(sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for sigma.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: current latent mean; scalar value in (0, inf);\n",
    "    sigma_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    gamma_mean: prior mean; scalar value in Reals;\n",
    "    gamma_spread: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    A1 = joint_log_probability_sigma(guessVector, mu, sigma_star, thetas, gamma_mean, gamma_spread,\n",
    "                        printing=printing, debug=debug)\n",
    "    A2 = joint_log_probability_sigma(guessVector, mu, sigma, thetas, gamma_mean, gamma_spread,\n",
    "                        printing=printing, debug=debug)\n",
    "    \n",
    "    A3 = sigma_log_jump_probs(sigma, sigma_star, sigma_prop, printing=printing, debug=debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if printing: \n",
    "        print_fn(['sigma', sigma, 'sigma_star', sigma_star, 'guessVector', guessVector, 'mu', mu, \n",
    "                  'thetas', thetas, 'gamma_mean', gamma_mean, 'gamma_spread', gamma_spread, 'sigma_prop', sigma_prop,\n",
    "                  'A1', A1, 'A2', A2, 'A3', A3, 'A', A])\n",
    "        \n",
    "    if A > 0: # if more probably (in log space), always jump\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(A)\n",
    "    \n",
    "def theta_accept(theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, \n",
    "                 lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for theta. A bit inefficient. Note, have to monitor\n",
    "    here for -infs, as sometimes the proposals reverse order sloppily. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: a current threshold; scalar value in (0, inf);\n",
    "    theta_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "\n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    thetasTemp = thetas.copy()\n",
    "    thetasTemp[center] = theta_star\n",
    "    \n",
    "    A1 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetasTemp, shift, sigma_0,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A2 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_0,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A3 = theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "\n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if debug:\n",
    "        if np.isneginf(A):\n",
    "            print('A is -inf: A {}; A1 {} A2 {} A3 {}'.format(A, A1, A2, A3))\n",
    "    if printing: \n",
    "        print_fn(['theta', theta, 'theta_star', theta_star, 'thetas', thetas, 'guessMatrix', guessMatrix,\n",
    "                  'A1', A1, 'A2', A2, 'A3', A3, 'A', A])\n",
    "    if np.isneginf(A):\n",
    "        return 0.0 # do not move if that would swap a threshold\n",
    "    else:\n",
    "        if A > 0: # if more probably (in log space), always jump\n",
    "            return 1\n",
    "        else:\n",
    "            return np.exp(A)\n",
    "\n",
    "        \n",
    "class SamplingFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def gamma(self, x, gamma_mean, gamma_spread, printing=False):\n",
    "        \"\"\"Return probability under gamma distribution.\"\"\"\n",
    "        alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "        beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "        \n",
    "        term_1 = (beta**alpha)\n",
    "        term_2 = 1/gamma_fn(alpha)\n",
    " \n",
    "        term_3 = (x**(alpha-1)) \n",
    "        term_4 = np.exp(-beta*x)\n",
    "        if printing:\n",
    "            print('exterior alpha, beta', alpha, beta)\n",
    "        #print_fn([\"term_1\", term_1, \"term_2\", term_2, \"term_3\", term_3, \"term_4\", term_4])\n",
    "        return term_1*term_2*term_3*term_4\n",
    "    \n",
    "    def test_mu_accept(self):\n",
    "        #             mu. mu_star  y.    sigma         thetas             mu_0 s_0  s_j\n",
    "        testValues = [0.0, 1.0, [1, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0, 2.0]\n",
    "        mu, mu_star, guessVector, sigma, thetas, mu_0, s_0, s_j = testValues.copy()\n",
    "        \n",
    "        returned_A = mu_accept(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([stats.norm.cdf(1.5, mu_star, sigma), \n",
    "                                stats.norm.cdf(2.5, mu_star, sigma) - stats.norm.cdf(1.5, mu_star, sigma),\n",
    "                                self.gauss(mu_star, mu_0, s_0)]))\n",
    "        real_A2 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma), \n",
    "                                stats.norm.cdf(2.5, mu, sigma) - stats.norm.cdf(1.5, mu, sigma),\n",
    "                                self.gauss(mu, mu_0, s_0)]))\n",
    "        \n",
    "        real_A3 = 0\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        \n",
    "    def test_sigma_accept(self):\n",
    "        # remember you changed the likelihood functions to take counts\n",
    "        #             s.  s_star  y.    mu         thetas                gamma_mean gamma_spread sigma_prop\n",
    "        testValues = [1.0, 2.0, [1, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 2.0, 3.0, 2.0]\n",
    "        sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread, sigma_prop = testValues.copy()\n",
    "        returned_A = sigma_accept(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma_star), \n",
    "                                stats.norm.cdf(2.5, mu, sigma_star) - stats.norm.cdf(1.5, mu, sigma_star),\n",
    "                                self.gamma(sigma_star, gamma_mean, gamma_spread)]))\n",
    "        real_A2 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma), \n",
    "                                stats.norm.cdf(2.5, mu, sigma) - stats.norm.cdf(1.5, mu, sigma),\n",
    "                                self.gamma(sigma, gamma_mean, gamma_spread)]))\n",
    "        \n",
    "        # sigma_log_jump_probs(sigma, sigma_star, sigma_prop, printing=printing, debug=debug)\n",
    "#         print('external term 1', np.log(self.gauss_trunc(sigma, sigma_star, \n",
    "#                                           sigma_prop, 0, 100)),\n",
    "#              'external term 2', np.log(self.gauss_trunc(sigma_star, sigma, \n",
    "#                                                                                    sigma_prop, 0, 100)))\n",
    "        real_A3 = np.log(self.gauss_trunc(sigma, sigma_star, \n",
    "                                          sigma_prop, 0, 100)) - np.log(self.gauss_trunc(sigma_star, sigma, \n",
    "                                                                                   sigma_prop, 0, 100)) # because asymmetric ---> Metropolis-H \n",
    "#         print_fn(['real_A1', real_A1, 'real_A2', real_A2, 'real_A3', real_A3])\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "    def test_theta_accept(self):\n",
    "        # in this case proposal is in order\n",
    "        testValues1 = [2.5, 2.6, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[1, 1], [0, 1, 1]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues1.copy()\n",
    "        returned_A = theta_accept(*testValues1, printing=False, debug=True)\n",
    "        thetasStar = thetas.copy()\n",
    "        thetasStar[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.6, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.6, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.6, mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.5, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.5, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.5, mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbsStar))\n",
    "        \n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        # in this case theta proposal is out of order\n",
    "        testValues2 = [2.5, 1.3, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[1, 1], [0, 1, 1]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues2.copy()\n",
    "        returned_A2 = theta_accept(*testValues2, printing=False, debug=True)\n",
    "        thetasStar2 = thetas.copy()\n",
    "        thetasStar2[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(1.3, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(1.3, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(1.3, mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar2[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.5, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.5, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.5, mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbs = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetas[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbs))\n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb2 = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A2, comb2)\n",
    "    \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(SamplingFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c54da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adf936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc91eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
