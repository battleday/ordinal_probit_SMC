{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.011s\n",
      "\n",
      "OK\n",
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.010s\n",
      "\n",
      "OK\n",
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.011s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Sampling functions and checks\n",
    "This notebook is to be used as a submodule that contains all the acceptance functions used by the MCMC component of the ordinal probit model for survey data, (Metropolis-Hastings sampler). It draws on the functions in helper_fns, probability_fns, and likelihood_fns. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_75349/1839039262.py:51: RuntimeWarning: divide by zero encountered in log\n",
      "  LLQ += counts * np.log(prob) # this means fewer calls to lookup table\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_75349/110277214.py:253: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP_1 = np.sum(np.log([max(0,\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some thetas out of order: [-inf, 1.5, 1.3, 3.5, inf]; test: [False  True False False  True]\n",
      "np.inf returned; should only really happen with thetas out of order:[-inf, 1.5, 1.3, 3.5, inf]\n",
      "LL: -inf\n",
      "LP: -3.4768155996140178\n",
      "A is -inf: A -inf; A1 -inf A2 -6.92554331291155 A3 -0.2255550003176261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.019s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_accept(mu, mu_star, guessVector, sigma, thetas, mu_0, sigma_0, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for mu.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: scalar value in Reals; current latent mean; \n",
    "    mu_star: scalar value in Reals; proposal for new latent mean; \n",
    "    guessVector: counts of guesses / y's for question. Each should be an integer / count; could be list or vector of ints;\n",
    "    sigma: scalar value in negative Reals; latent sd; \n",
    "    thetas: scalars in [1.5, k-0.5]; values of latent thresholds defining probit probabilities; \n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: scalar value in Reals; prior mean for mus; \n",
    "    sigma_0: scalar value in positive reals; prior standard devation for mus; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); either 1 or scalar between 0 and 1.\n",
    "    \"\"\"\n",
    "    \n",
    "    A1 = joint_log_probability_mu(guessVector, mu_star, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = mu_log_jump_probs(mu, mu_star, sigma_prop, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "\n",
    "    if A > 0: # if more probably (in log space), always jump\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(A)\n",
    "\n",
    "def sigma_accept(sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread, sigma_prop,\n",
    "                 lower_sigma, upper_sigma,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for sigma.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: scalar value in positive Reals; current latent sd; \n",
    "    sigma_star: scalar value in positive Reals; proposal for new latent sd; \n",
    "    guessVector: counts of guesses / y's for question. Each should be an integer / count; could be list or vector of ints;\n",
    "    mu: scalar value in Reals; latent mean; \n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    gamma_mean: scalar value in Reals; prior mean for sigma; \n",
    "    gamma_spread: scalar value in positive Reals; prior standard devation for sigma; \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); either 1 or scalar between 0 and 1.\n",
    "    \"\"\"\n",
    "    A1 = joint_log_probability_sigma(guessVector, mu, sigma_star, thetas, gamma_mean, gamma_spread,\n",
    "                        printing=printing, debug=debug)\n",
    "    A2 = joint_log_probability_sigma(guessVector, mu, sigma, thetas, gamma_mean, gamma_spread,\n",
    "                        printing=printing, debug=debug)\n",
    "    \n",
    "    A3 = sigma_log_jump_probs(sigma, sigma_star, sigma_prop, lower_sigma, \n",
    "                              upper_sigma, printing=printing, debug=debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if printing: \n",
    "        print_fn(['sigma', sigma, 'sigma_star', sigma_star, 'guessVector', guessVector, 'mu', mu, \n",
    "                  'thetas', thetas, 'gamma_mean', gamma_mean, 'gamma_spread', gamma_spread, 'sigma_prop', sigma_prop,\n",
    "                  'A1', A1, 'A2', A2, 'A3', A3, 'A', A])\n",
    "        \n",
    "    if A > 0: # if more probably (in log space), always jump\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(A)\n",
    "    \n",
    "def theta_accept(theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, \n",
    "                 lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for theta. A bit inefficient/I'm sure there could\n",
    "    be some cancellations. \n",
    "    \n",
    "    N.B., have to monitor here for -infs, as sometimes the proposals reverse order sloppily as per the original\n",
    "    paper.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: scalar in [1.5, k-0.5]; a current threshold; \n",
    "    theta_star: scalar in [1.5, k-0.5]; proposal for new latent mean; \n",
    "    thetas: scalars in [1.5, k-0.5]; values of latent thresholds defining probit probabilities; \n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "            \n",
    "    guessMatrix: rows: questions, columns, counts of guesses / y's . Each should be an integer / count; could be list of lists or matrix of ints;\n",
    "    mus: scalar vector of length # questions in Reals; latent means for all question; \n",
    "    sigmas: scalar vector of length # questions in positive Reals; latent sds for all questions; \n",
    "    center: integer in [2, k-2], which theta we are updating (others fixed);\n",
    "    shift:  scalar value in Reals; to add to prior means to center intervals; pretty much always 0.5;\n",
    "    sigma_0: scalar value in positive Reals; prior standard devation for thetas;\n",
    "    \n",
    "    sigma_prop: scalar value in positive Reals; sd of jump distribution (trunc normal);\n",
    "    lower_0: lower boundary or trunc normal (usually 1.5)\n",
    "    upper_0: upper boundary of trunc normal (usually k-0.5)\n",
    "    \n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "\n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); 1 or scalar in (0, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    thetasTemp = thetas.copy()\n",
    "    thetasTemp[center] = theta_star\n",
    "    \n",
    "    A1 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetasTemp, shift, sigma_0,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A2 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_0,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A3 = theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "\n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if debug:\n",
    "        assert 1 < center < thetas[-2], \"center to be updated is not 2:k-1; {}\".format(center)\n",
    "        if np.isneginf(A):\n",
    "            print('A is -inf: A {}; A1 {} A2 {} A3 {}'.format(A, A1, A2, A3))\n",
    "    if printing: \n",
    "        print_fn(['theta', theta, 'theta_star', theta_star, 'thetas', thetas, 'guessMatrix', guessMatrix,\n",
    "                  'A1', A1, 'A2', A2, 'A3', A3, 'A', A])\n",
    "    if np.isneginf(A): # this is an important, if hacky, step---to avoid thresholds swapping during MCMC.\n",
    "        return 0.0 # do not move if that would swap a threshold\n",
    "    else:\n",
    "        if A > 0: # if more probably (in log space), always jump\n",
    "            return 1\n",
    "        else:\n",
    "            return np.exp(A)\n",
    "\n",
    "        \n",
    "class SamplingFunctionsTestSuite(unittest.TestCase):\n",
    "    \"\"\"This is a testing suite for the above functions. Usually only one hand-worked test\n",
    "    per function. All working fine at time of build. \n",
    "    \n",
    "    Any modification to one of these function's inputs, function, or output will require\n",
    "    a modification to the corresponding example. If so, turn printing and debug on to work through.\n",
    "    \"\"\"\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def gamma(self, x, gamma_mean, gamma_spread, printing=False):\n",
    "        \"\"\"Return probability under gamma distribution.\"\"\"\n",
    "        alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "        beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "        \n",
    "        term_1 = (beta**alpha)\n",
    "        term_2 = 1/gamma_fn(alpha)\n",
    " \n",
    "        term_3 = (x**(alpha-1)) \n",
    "        term_4 = np.exp(-beta*x)\n",
    "        if printing:\n",
    "            print('exterior alpha, beta', alpha, beta)\n",
    "        return term_1*term_2*term_3*term_4\n",
    "    \n",
    "    def test_mu_accept(self):\n",
    "        #             mu. mu_star  y.    sigma         thetas             mu_0 s_0  s_j\n",
    "        testValues = [0.0, 1.0, [1, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0, 2.0]\n",
    "        mu, mu_star, guessVector, sigma, thetas, mu_0, s_0, s_j = testValues.copy()\n",
    "        \n",
    "        returned_A = mu_accept(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([stats.norm.cdf(1.5, mu_star, sigma), \n",
    "                                stats.norm.cdf(2.5, mu_star, sigma) - stats.norm.cdf(1.5, mu_star, sigma),\n",
    "                                self.gauss(mu_star, mu_0, s_0)]))\n",
    "        real_A2 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma), \n",
    "                                stats.norm.cdf(2.5, mu, sigma) - stats.norm.cdf(1.5, mu, sigma),\n",
    "                                self.gauss(mu, mu_0, s_0)]))\n",
    "        \n",
    "        real_A3 = 0\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        \n",
    "    def test_sigma_accept(self):\n",
    "        # remember you changed the likelihood functions to take counts\n",
    "        #             s.  s_star  y.    mu         thetas                gamma_mean gamma_spread sigma_prop lower_sigma, upper_sigma\n",
    "        testValues = [1.0, 2.0, [1, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 2.0, 3.0, 2.0, 0, 100]\n",
    "        sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread, sigma_prop, lower_sigma, upper_sigma = testValues.copy()\n",
    "        returned_A = sigma_accept(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma_star), \n",
    "                                stats.norm.cdf(2.5, mu, sigma_star) - stats.norm.cdf(1.5, mu, sigma_star),\n",
    "                                self.gamma(sigma_star, gamma_mean, gamma_spread)]))\n",
    "        real_A2 = np.sum(np.log([stats.norm.cdf(1.5, mu, sigma), \n",
    "                                stats.norm.cdf(2.5, mu, sigma) - stats.norm.cdf(1.5, mu, sigma),\n",
    "                                self.gamma(sigma, gamma_mean, gamma_spread)]))\n",
    "        \n",
    "        real_A3 = np.log(self.gauss_trunc(sigma, sigma_star, \n",
    "                                          sigma_prop, 0, 100)) - np.log(self.gauss_trunc(sigma_star, sigma, \n",
    "                                                                                   sigma_prop, 0, 100)) # because asymmetric ---> Metropolis-H \n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "    def test_theta_accept(self):\n",
    "        # in this case proposal is in order\n",
    "        testValues1 = [2.5, 2.6, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[1, 1], [0, 1, 1]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues1.copy()\n",
    "        returned_A = theta_accept(*testValues1, printing=False, debug=True)\n",
    "        thetasStar = thetas.copy()\n",
    "        thetasStar[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.6, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.6, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.6, mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.5, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.5, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.5, mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbsStar))\n",
    "        \n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        # in this case theta proposal is out of order\n",
    "        testValues2 = [2.5, 1.3, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[1, 1], [0, 1, 1]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues2.copy()\n",
    "        returned_A2 = theta_accept(*testValues2, printing=False, debug=True)\n",
    "        thetasStar2 = thetas.copy()\n",
    "        thetasStar2[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(1.3, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(1.3, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(1.3, mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar2[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(1.5, mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(2.5, mus[0], sigmas[0]) - stats.norm.cdf(1.5, mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(2.5, mus[1], sigmas[1]) - stats.norm.cdf(1.5, mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(3.5, mus[1], sigmas[1]) - stats.norm.cdf(2.5, mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbs = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetas[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbs))\n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb2 = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A2, comb2)\n",
    "    \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(SamplingFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c54da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9adf936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc91eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
