{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286c9f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.010s\n",
      "\n",
      "OK\n",
      "...........\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.010s\n",
      "\n",
      "OK\n",
      "......"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end is lower than start; can happen and will return 0 which will cause neg infs later: [-inf, 0.0, -1.0, 1.0, inf]\n",
      "in theta prior\n",
      "\n",
      " theta has value 1.5\n",
      "\n",
      " mu_0 has value 1.5\n",
      "\n",
      " 1.0 has value sigma_0\n",
      "in theta prior\n",
      "\n",
      " theta has value 2.5\n",
      "\n",
      " mu_0 has value 2.5\n",
      "\n",
      " 1.0 has value sigma_0\n",
      "\n",
      " sigma_0 has value 1.0\n",
      "\n",
      " ks plus shift has value [1.5, 2.5]\n",
      "\n",
      " thetas has value [-inf, 1.5, 2.5, inf]\n",
      "\n",
      " thetaPriors has value [0.3989422804014327, 0.3989422804014327]\n",
      "\n",
      " theta log prior internal has value -1.8378770664093453\n",
      "\n",
      " thetas has value [-inf, 1.5, 2.5, inf]\n",
      "\n",
      " shift has value 0.5\n",
      "\n",
      " sigma_0 has value 1.0\n",
      "\n",
      " LP has value -1.8378770664093453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.013s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import unittest\n",
    "%run helper_fns.ipynb\n",
    "%run probability_fns.ipynb\n",
    "%run likelihood_fns.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a84d76",
   "metadata": {},
   "source": [
    "## Likelihood functions and checks\n",
    "This notebook is to be used as a submodule that contains wrappers for all the likelihood functions used by the ordinal probit model for survey data, and Metropolis-Hastings sampler. There is also an optional testing suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1825b915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_70526/4114300579.py:49: RuntimeWarning: divide by zero encountered in log\n",
      "  LLQ += np.log(LOP(y, mu, sigma, thetas))\n",
      "/var/folders/z3/65sxpv5n3csdhfzm0ysx30940000gp/T/ipykernel_70526/3187598881.py:232: RuntimeWarning: divide by zero encountered in log\n",
      "  real_LP_1 = np.sum(np.log([max(0,\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some thetas out of order: [-inf, 1.5, 1.3, 3.5, inf]; test: [False  True False False  True]\n",
      "np.inf returned; should only really happen with thetas out of order:[-inf, 1.5, 1.3, 3.5, inf]\n",
      "LL: -inf\n",
      "LP: -3.4768155996140178\n",
      "A is -inf: A -inf; A1 -inf A2 -6.92554331291155 A3 -0.2255550003176261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.018s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mu_accept(mu, mu_star, guessVector, sigma, thetas, mu_0, sigma_0, sigma_prop,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for mu.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    mu: current latent mean; scalar value in Reals;\n",
    "    mu_star: proposal for new latent mean; scalar value in Reals;\n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    sigma: latent sd; scalar value in (0, inf);\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    A1 = joint_log_probability_mu(guessVector, mu_star, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_mu(guessVector, mu, sigma, thetas, mu_0, sigma_0, \n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = mu_log_jump_probs(mu, mu_star, sigma_prop, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "def sigma_accept(sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread,\n",
    "             printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for sigma.\n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    sigma: current latent mean; scalar value in (0, inf);\n",
    "    sigma_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    gamma_mean: prior mean; scalar value in Reals;\n",
    "    gamma_spread: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "    \n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    A1 = joint_log_probability_sigma(guessVector, mu, sigma_star, thetas, gamma_mean, gamma_spread,\n",
    "                        printing, debug)\n",
    "    A2 = joint_log_probability_sigma(guessVector, mu, sigma, thetas, gamma_mean, gamma_spread,\n",
    "                        printing, debug)\n",
    "    \n",
    "    A3 = sigma_log_jump_probs(sigma, sigma_star, gamma_spread, printing, debug)\n",
    "    \n",
    "    A = A1 - A2 + A3\n",
    "    return min(1, np.exp(A))\n",
    "\n",
    "def theta_accept(theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, \n",
    "                 lower_0, upper_0, printing=False, debug=False):\n",
    "    \"\"\"Returns the acceptance probability of a proposal for theta. A bit inefficient. Note, have to monitor\n",
    "    here for -infs, as sometimes the proposals reverse order sloppily. \n",
    "    \n",
    "    Inputs\n",
    "    -------------------\n",
    "    theta: a current threshold; scalar value in (0, inf);\n",
    "    theta_star: proposal for new latent mean; scalar value in (0, inf); \n",
    "    guessVector: guesses / y's. Each should be an integer from 1:k; could be list or vector of ints;\n",
    "    mu: latent mean; scalar value in Reals;\n",
    "    thetas: values of latent thresholds defining probit probabilities; scalars in [1.5, k-0.5];\n",
    "            endpoints are -inf, inf. Length is k+2, where k is the number of possible ordinal choices.\n",
    "    mu_0: prior mean; scalar value in Reals;\n",
    "    sigma_0: prior standard devation; scalar value in (0, inf);\n",
    "    printing: Bool; whether to print messages;\n",
    "    debug: Bool; whether to run internal error checks.\n",
    "\n",
    "    Outputs\n",
    "    -------------------\n",
    "    AP: acceptance probability (ratio); scalar in (0, inf).\n",
    "    \"\"\"\n",
    "    \n",
    "    thetasTemp = thetas.copy()\n",
    "    thetasTemp[center] = theta_star\n",
    "    \n",
    "    A1 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetasTemp, shift, sigma_prop,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A2 = joint_log_probability_thetas(guessMatrix, mus, sigmas, thetas, shift, sigma_prop,\n",
    "                                     printing, debug)\n",
    "    \n",
    "    A3 = theta_log_jump_probs(theta, theta_star, sigma_prop, lower_0, upper_0, printing, debug)\n",
    "\n",
    "    A = A1 - A2 + A3\n",
    "    \n",
    "    if debug:\n",
    "        if np.isneginf(A):\n",
    "            print('A is -inf: A {}; A1 {} A2 {} A3 {}'.format(A, A1, A2, A3))\n",
    "    if printing: \n",
    "        print(\"A1 {} A2 {} A3 {}\".format(A1, A2, A3))\n",
    "    if np.isneginf(A):\n",
    "        return 0.0 # do not move if that would swap a threshold\n",
    "    else:\n",
    "        return min(1, np.exp(A))\n",
    "    \n",
    "def update_parameter(param_name, proposal_fn, proposalParams, acceptance_fn, acceptanceParams): \n",
    "    \"\"\"Generic update function for a parameter.\"\"\"\n",
    "    \n",
    "    proposal = proposal_fn(*proposalParams)\n",
    "    accept = acceptance_fn(*acceptanceParams)\n",
    "    ru = np.random.uniform()\n",
    "    if accept > ru:\n",
    "        return proposal\n",
    "    else:\n",
    "        return param\n",
    "        \n",
    "class LikelihoodFunctionsTestSuite(unittest.TestCase):\n",
    "    def gauss(self, val, mu=0, s=1):\n",
    "            return np.exp(- (1/2)*\n",
    "                          ((val-mu)/s)**2) / np.sqrt(2*np.pi*(s**2))\n",
    "    \n",
    "    def gauss_trunc(self, x, mu, sigma, lower, upper):\n",
    "        zeta = (x-mu)/sigma\n",
    "        alpha = (lower-mu)/sigma\n",
    "        beta = (upper-mu)/sigma\n",
    "        Z = stats.norm.cdf(beta) - stats.norm.cdf(alpha)\n",
    "        return (self.gauss(zeta)) / (sigma*Z)\n",
    "    \n",
    "    def gamma(self, x, gamma_mean, gamma_spread, printing=False):\n",
    "        \"\"\"Return probability under gamma distribution.\"\"\"\n",
    "        alpha = (gamma_mean**2) / (gamma_spread**2) # shape param, algebra from wikipedia\n",
    "        beta = gamma_mean / (gamma_spread**2) # algebra from wikipedia\n",
    "        \n",
    "        term_1 = (beta**alpha)\n",
    "        term_2 = 1/gamma_fn(alpha)\n",
    " \n",
    "        term_3 = (x**(alpha-1)) \n",
    "        term_4 = np.exp(-beta*x)\n",
    "        if printing:\n",
    "            print('exterior alpha, beta', alpha, beta)\n",
    "        #print_fn([\"term_1\", term_1, \"term_2\", term_2, \"term_3\", term_3, \"term_4\", term_4])\n",
    "        return term_1*term_2*term_3*term_4\n",
    "    \n",
    "    def test_mu_accept(self):\n",
    "        #             mu. mu_star  y.    sigma         thetas             mu_0 s_0  s_j\n",
    "        testValues = [0.0, 1.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 1.0, 1.0, 2.0]\n",
    "        mu, mu_star, guessVector, sigma, thetas, mu_0, s_0, s_j = testValues.copy()\n",
    "        \n",
    "        returned_A = mu_accept(*testValues, printing=False, debug=True)\n",
    "        \n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu_star, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu_star, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu_star, sigma)),\n",
    "                                self.gauss(mu_star, mu_0, s_0)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                self.gauss(mu, mu_0, s_0)]))\n",
    "        \n",
    "        real_A3 = 0\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        \n",
    "    def test_sigma_accept(self):\n",
    "        #             s.  s_star  y.    mu         thetas                gamma_mean gamma_spread\n",
    "        testValues = [1.0, 2.0, [2, 1], 2.0, [-np.inf, 1.5, 2.5, np.inf], 2.0, 3.0]\n",
    "        sigma, sigma_star, guessVector, mu, thetas, gamma_mean, gamma_spread = testValues.copy()\n",
    "        returned_A = sigma_accept(*testValues, printing=False, debug=True)\n",
    "        real_A1 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma_star)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma_star) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma_star)),\n",
    "                                self.gamma(sigma_star, gamma_mean, gamma_spread)]))\n",
    "        real_A2 = np.sum(np.log([max(0, stats.norm.cdf(thetas[guessVector[0]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[0]], mu, sigma)), \n",
    "                                max(0, stats.norm.cdf(thetas[guessVector[1]+1], mu, sigma) - stats.norm.cdf(thetas[guessVector[1]], mu, sigma)),\n",
    "                                self.gamma(sigma, gamma_mean, gamma_spread)]))\n",
    "        # this still needs changing\n",
    "        real_A3 = np.log(self.gamma(sigma, sigma_star, gamma_spread)) - np.log(self.gamma(sigma_star, sigma, gamma_spread)) # because asymmetric ---> Metropolis-H \n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "    def test_theta_accept(self):\n",
    "        # in this case proposal is in order\n",
    "        testValues1 = [2.5, 2.6, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[2, 1], [2, 3]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues1.copy()\n",
    "        returned_A = theta_accept(*testValues1, printing=False, debug=True)\n",
    "        thetasStar = thetas.copy()\n",
    "        thetasStar[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(thetasStar[guessMatrix[0][0]], mus[0], sigmas[0]) - stats.norm.cdf(thetasStar[guessMatrix[0][0]-1], mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetasStar[guessMatrix[0][1]], mus[0], sigmas[0]) - stats.norm.cdf(thetasStar[guessMatrix[0][1]-1], mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(thetasStar[guessMatrix[1][0]], mus[1], sigmas[1]) - stats.norm.cdf(thetasStar[guessMatrix[1][0]-1], mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetasStar[guessMatrix[1][1]], mus[1], sigmas[1]) - stats.norm.cdf(thetasStar[guessMatrix[1][1]-1], mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(thetas[guessMatrix[0][0]], mus[0], sigmas[0]) - stats.norm.cdf(thetas[guessMatrix[0][0]-1], mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetas[guessMatrix[0][1]], mus[0], sigmas[0]) - stats.norm.cdf(thetas[guessMatrix[0][1]-1], mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(thetas[guessMatrix[1][0]], mus[1], sigmas[1]) - stats.norm.cdf(thetas[guessMatrix[1][0]-1], mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetas[guessMatrix[1][1]], mus[1], sigmas[1]) - stats.norm.cdf(thetas[guessMatrix[1][1]-1], mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbsStar))\n",
    "        \n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A, comb)\n",
    "        \n",
    "        # in this case theta proposal is out of order\n",
    "        testValues2 = [2.5, 1.3, [-np.inf, 1.5, 2.5, 3.5, np.inf], [[2, 1], [2, 3]], [1.0, 2.0], [1.0, 1.0], 2, 0.5, 1.0, 1.0, 0, 3]\n",
    "        theta, theta_star, thetas, guessMatrix, mus, sigmas, center, shift, sigma_0, sigma_prop, lower_0, upper_0 = testValues2.copy()\n",
    "        returned_A2 = theta_accept(*testValues2, printing=False, debug=True)\n",
    "        thetasStar2 = thetas.copy()\n",
    "        thetasStar2[center] = theta_star\n",
    "        \n",
    "        real_LP_1 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(thetasStar2[guessMatrix[0][0]], mus[0], sigmas[0]) - stats.norm.cdf(thetasStar2[guessMatrix[0][0]-1], mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetasStar2[guessMatrix[0][1]], mus[0], sigmas[0]) - stats.norm.cdf(thetasStar2[guessMatrix[0][1]-1], mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(thetasStar2[guessMatrix[1][0]], mus[1], sigmas[1]) - stats.norm.cdf(thetasStar2[guessMatrix[1][0]-1], mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetasStar2[guessMatrix[1][1]], mus[1], sigmas[1]) - stats.norm.cdf(thetasStar2[guessMatrix[1][1]-1], mus[1], sigmas[1]))]))\n",
    "        \n",
    "        \n",
    "        tempProbsStar = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetasStar2[1:-1])]\n",
    "        real_LP_2 = np.sum(np.log(tempProbsStar))\n",
    "\n",
    "        \n",
    "        real_LP_3 = np.sum(np.log([max(0, \n",
    "                                       stats.norm.cdf(thetas[guessMatrix[0][0]], mus[0], sigmas[0]) - stats.norm.cdf(thetas[guessMatrix[0][0]-1], mus[0], sigmas[0])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetas[guessMatrix[0][1]], mus[0], sigmas[0]) - stats.norm.cdf(thetas[guessMatrix[0][1]-1], mus[0], sigmas[0])),\n",
    "                                   max(0, \n",
    "                                       stats.norm.cdf(thetas[guessMatrix[1][0]], mus[1], sigmas[1]) - stats.norm.cdf(thetas[guessMatrix[1][0]-1], mus[1], sigmas[1])), \n",
    "                                max(0, \n",
    "                                    stats.norm.cdf(thetas[guessMatrix[1][1]], mus[1], sigmas[1]) - stats.norm.cdf(thetas[guessMatrix[1][1]-1], mus[1], sigmas[1]))]))\n",
    "         \n",
    "        tempProbs = [self.gauss(x, i+1.5, sigma_0) for (i, x) in enumerate(thetas[1:-1])]\n",
    "\n",
    "        real_LP_4 = np.sum(np.log(tempProbs))\n",
    "        \n",
    "        real_A1 = real_LP_1 + real_LP_2\n",
    "        real_A2 = real_LP_3 + real_LP_4\n",
    "        real_A3 = np.log(self.gauss_trunc(theta, theta_star, sigma_prop, lower_0, upper_0)) - np.log(self.gauss_trunc(theta_star, theta, sigma_prop, lower_0, upper_0))\n",
    "        comb2 = np.min([1, np.exp(real_A1 - real_A2 + real_A3)])\n",
    "        self.assertAlmostEqual(returned_A2, comb2)\n",
    "    \n",
    "runner = unittest.TextTestRunner(failfast=True)\n",
    "runner.run(initialize_suite(LikelihoodFunctionsTestSuite))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c54da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
